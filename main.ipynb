{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from qiskit import ClassicalRegister, QuantumRegister\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit.circuit.library import RealAmplitudes\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\n",
    "from qiskit.extensions import RZGate, CXGate\n",
    "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit.circuit.library import EfficientSU2\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_globals.random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'FMNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_latent = 4\n",
    "num_trash = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (8,8)\n",
    "image_pixels = image_shape[0]*image_shape[1]\n",
    "\n",
    "num_samples = 25\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = num_samples*num_classes\n",
    "projection_units = 32\n",
    "temperature = 0.1\n",
    "\n",
    "tolerance = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"DATASET_{}-IMG_{}-CLASSES_{}-SAMPLES_{}-BATCH_{}-PROJUNITS_{}-TEMP_{}-LATENT_{}-TRASH_{}\".\\\n",
    "format(dataset, str(image_shape[0])+\"X\"+str(image_shape[1]), num_classes, num_samples, batch_size, projection_units, temperature, num_latent,\n",
    "       num_trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('experiments/{}'.format(experiment_name))\n",
    "except FileExistsError:\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = 'experiments/{}'.format(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implement SupCon Learning Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![q-sup-con](./images/q_sup_con_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Quantum Encoder Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz(num_qubits):\n",
    "    return RealAmplitudes(num_qubits, reps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_encoder_circuit(num_latent, num_trash):\n",
    "    qr = QuantumRegister(num_latent + 2 * num_trash + 1, \"q\")\n",
    "    cr = ClassicalRegister(1, \"c\")\n",
    "    circuit = QuantumCircuit(qr, cr)\n",
    "    circuit.compose(ansatz(num_latent + num_trash), range(0, num_latent + num_trash), inplace=True)\n",
    "    circuit.barrier()\n",
    "    auxiliary_qubit = num_latent + 2 * num_trash\n",
    "    # swap test\n",
    "    circuit.h(auxiliary_qubit)\n",
    "    for i in range(num_trash):\n",
    "        circuit.cswap(auxiliary_qubit, num_latent + i, num_latent + num_trash + i)\n",
    "\n",
    "    circuit.h(auxiliary_qubit)\n",
    "    circuit.measure(auxiliary_qubit, cr[0])\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation_circuit(num_latent, num_trash):\n",
    "    num_qubits = num_latent + num_trash\n",
    "    if num_qubits < 1:\n",
    "        raise ValueError(\"Number of qubits must be at least 1.\")\n",
    "\n",
    "    qreg_q = QuantumRegister(num_latent + 2 * num_trash + 1, \"q\")\n",
    "    # creg_c = ClassicalRegister(1, 'c')\n",
    "    circuit = QuantumCircuit(qreg_q)\n",
    "    # circuit.compose(ansatz(num_latent + num_trash), range(0, num_latent + num_trash), inplace=True)\n",
    "\n",
    "    for i in range(num_qubits):\n",
    "        circuit.sx(qreg_q[i])\n",
    "        circuit.append(RZGate(np.pi / 2), [qreg_q[i]])\n",
    "        circuit.sx(qreg_q[i])\n",
    "        circuit.append(RZGate(np.pi / 2), [qreg_q[i]])\n",
    "\n",
    "        if i < num_qubits - 1:\n",
    "            circuit.append(CXGate(), [qreg_q[i], qreg_q[i + 1]])\n",
    "\n",
    "        # circuit.measure(qreg_q[i], creg_c[0])\n",
    "\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations to apply to the MNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(image_shape)])\n",
    "\n",
    "# Download and load the MNIST training dataset\n",
    "full_mn_train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "full_fmn_train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "full_kmn_train_dataset = datasets.KMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "selected_dataset = full_fmn_train_dataset if dataset == 'FMNIST' else ( full_kmn_train_dataset if dataset == 'KMNIST' else full_mn_train_dataset)\n",
    "\n",
    "# Filter the dataset to get 25 samples of 0 and 25 samples of 1\n",
    "# Initialize an empty list to store indices\n",
    "selected_indices = []\n",
    "\n",
    "# Iterate through class labels 0 to 9\n",
    "for class_label in range(num_classes):\n",
    "    indices = torch.where(selected_dataset.targets == class_label)[0][:num_samples]\n",
    "    selected_indices.extend(indices.tolist())\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(selected_dataset, selected_indices)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterator from the DataLoader\n",
    "train_iter = iter(train_loader)\n",
    "# test_iter = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Quantum Supervised Conrastive Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Build QSCL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = RawFeatureVector(2 ** (num_latent + num_trash))\n",
    "\n",
    "d_aug = data_augmentation_circuit(num_latent, num_trash)\n",
    "\n",
    "ae = auto_encoder_circuit(num_latent, num_trash)\n",
    "\n",
    "qc = QuantumCircuit(num_latent + 2 * num_trash + 1, 1)\n",
    "qc = qc.compose(fm, range(num_latent + num_trash))\n",
    "qc = qc.compose(d_aug)\n",
    "qc = qc.compose(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_interpret(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_con_qnn = SamplerQNN(\n",
    "    circuit=qc,\n",
    "    input_params=fm.parameters,\n",
    "    weight_params=ae.parameters,\n",
    "    interpret=identity_interpret,\n",
    "    output_shape=projection_units,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Build Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Supervised Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_func_vals_sup_con = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func_digits_sup(params_values):\n",
    "    batch_images, batch_labels = batch\n",
    "\n",
    "    batch_images = np.array(batch_images.reshape(len(batch_images), image_pixels))\n",
    "\n",
    "    for i in range(len(batch_images)):\n",
    "        sum_sq = np.sum(batch_images[i] ** 2)\n",
    "        batch_images[i] = batch_images[i] / np.sqrt(sum_sq)\n",
    "    \n",
    "    # batch_images = (batch_images - batch_images.min()) / (batch_images.max() - batch_images.min()) * np.pi/2\n",
    "    probabilities = sup_con_qnn.forward(batch_images, params_values)\n",
    "    \n",
    "    # Normalize feature vectors\n",
    "    feature_vectors_magnitude = np.linalg.norm(probabilities, axis=1, ord=2, keepdims=True)\n",
    "    feature_vectors_normalized = probabilities / feature_vectors_magnitude\n",
    "    # Compute logits\n",
    "    logits = np.dot(feature_vectors_normalized, feature_vectors_normalized.T) / temperature\n",
    "\n",
    "    loss = -np.log(np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True))\n",
    "    loss = loss[np.arange(len(batch_labels)), np.array(batch_labels).squeeze()]\n",
    "    cost = np.mean(loss)\n",
    "\n",
    "    # plotting part\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals_sup_con.append(cost)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals_sup_con)), objective_func_vals_sup_con)\n",
    "    plt.show()\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_points = algorithm_globals.random.random(ae.num_parameters)\n",
    "try:\n",
    "    initial_points = np.load(experiment_folder+'/enc_initial_points.npy')\n",
    "except FileNotFoundError:\n",
    "    initial_points = algorithm_globals.random.random(ae.num_parameters)\n",
    "    np.save(experiment_folder+'/enc_initial_points.npy', np.array(initial_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 QSCL Encoder Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = COBYLA(maxiter=1000) # , tol=tolerance\n",
    "\n",
    "# make the plot nicer\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "start = time.time()\n",
    "opt_result = opt.minimize(cost_func_digits_sup, initial_points)\n",
    "elapsed = time.time() - start\n",
    "print(f\"Fit in {elapsed:0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(experiment_folder+'/enc_loss_values.npy', np.array(objective_func_vals_sup_con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_result_x = algorithm_globals.random.random(ae.num_parameters)\n",
    "try:\n",
    "    opt_result_x = np.load(experiment_folder+'/enc_opt_x.npy')\n",
    "except FileNotFoundError:\n",
    "    opt_result_x = algorithm_globals.random.random(ae.num_parameters)\n",
    "    np.save(experiment_folder+'/enc_opt_x.npy', np.array(opt_result.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Generate Feacture Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_qc = QuantumCircuit(num_latent + num_trash)\n",
    "test_qc = test_qc.compose(fm)\n",
    "ansatz_qc = ansatz(num_latent + num_trash)\n",
    "test_qc = test_qc.compose(ansatz_qc)\n",
    "test_qc.barrier()\n",
    "\n",
    "for i in range(num_latent, num_latent+num_trash):\n",
    "    test_qc.reset(i)\n",
    "# test_qc.barrier()\n",
    "# test_qc = test_qc.compose(ansatz_qc.inverse())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Generate Feacture Vector for Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = []\n",
    "y_encoded = []\n",
    "\n",
    "# sample new images\n",
    "# test_images, test_labels = get_dataset_digits(2, draw=False)\n",
    "for images, labels in train_loader:\n",
    "    for image in images:\n",
    "        image = np.array(image.reshape(image_pixels))\n",
    "\n",
    "        original_qc = fm.assign_parameters(image)\n",
    "        original_sv = Statevector(original_qc).data\n",
    "        original_sv = np.reshape(np.abs(original_sv) ** 2, image_shape)\n",
    "\n",
    "        param_values = np.concatenate((image, opt_result.x))\n",
    "        output_qc = test_qc.assign_parameters(param_values)\n",
    "        output_sv = Statevector(output_qc).data\n",
    "        output_sv = np.reshape(np.abs(output_sv) ** 2, image_pixels)\n",
    "\n",
    "        X_encoded.append(output_sv[:2**num_latent])\n",
    "    y_encoded.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 Generate Feacture Vector for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_qc2 = QuantumCircuit(num_latent + num_trash)\n",
    "test_qc2 = test_qc2.compose(fm)\n",
    "ansatz_qc2 = ansatz(num_latent + num_trash)\n",
    "test_qc2 = test_qc2.compose(ansatz_qc2)\n",
    "test_qc2.barrier()\n",
    "\n",
    "for i in range(num_latent, num_latent+num_trash):\n",
    "    test_qc2.reset(i)\n",
    "test_qc2.barrier()\n",
    "test_qc2 = test_qc2.compose(ansatz_qc2.inverse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = np.reshape(y_encoded, (len(y_encoded), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_np = np.concatenate((X_encoded, y_encoded), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_df = pd.DataFrame(X_y_np, columns =['f'+str(i) for i in range(2**num_latent)]+['y'])\n",
    "X_y_df.to_csv(experiment_folder+'/enc_df.csv') #dataset, image_size, num_samples, batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. VQC Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm2 = RawFeatureVector(2**num_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(experiment_folder+'/enc_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    np.array(df.iloc[:,:-1]), np.array(df.y), train_size=0.8, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_func_vals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback function that draws a live plot when the .fit() method is called\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sampler()\n",
    "\n",
    "ansatz = EfficientSU2(num_qubits=num_latent, reps=3)\n",
    "optimizer = COBYLA(maxiter=1)\n",
    "\n",
    "vqc = VQC(\n",
    "    sampler=sampler,\n",
    "    feature_map=fm2,\n",
    "    ansatz=ansatz,\n",
    "    optimizer=optimizer,\n",
    "    callback=callback_graph,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty array for callback to store evaluations of the objective function\n",
    "objective_func_vals = []\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# fit classifier to data\n",
    "\n",
    "start = time.time()\n",
    "vqc.fit(train_features, train_labels)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Training time: {round(elapsed)} seconds\")\n",
    "\n",
    "# return to default figsize\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_q2_eff = vqc.score(train_features, train_labels)\n",
    "test_score_q2_eff = vqc.score(test_features, test_labels)\n",
    "\n",
    "print(f\"Quantum VQC on the training dataset using EfficientSU2: {train_score_q2_eff:.2f}\")\n",
    "print(f\"Quantum VQC on the test dataset using EfficientSU2:     {test_score_q2_eff:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(experiment_folder+'/clasif_loss_values.npy', np.array(objective_func_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(experiment_folder+'/results.txt', 'w') as file:\n",
    "    file.write(f'{vqc.score(train_features, train_labels)}\\n')\n",
    "    file.write(f'{vqc.score(test_features, test_labels)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqc.save(experiment_folder+'/classifire.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
